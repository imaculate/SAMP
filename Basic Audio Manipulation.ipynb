{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instructions:\n",
      "\n",
      "Run each of the python kernels below (in order). You can rerun a kernel (for example file loading if you need to reset or readjust values). Feel free to play around."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Accreditation:\n",
      "\n",
      "Celtic Collection (C) Adrian Von Ziegler (https://www.youtube.com/watch?v=jiwuQ6UHMQg)\n",
      "\n",
      "1984 Chapter 2 (C) George Orwel, Recorded Books Inc. (https://archive.org/details/George-Orwell-1984-Audio-book)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Imports\n",
      "import pyaudio as pa\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "import time\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Simple Audio Loading"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "RAW PCM audio files are simply collections of t x samples_per_second x channels amplitudes, where each amplitude is rounded and encoded as a signed 8/16/24/32 bit integer. All we need to know is the file size, the samples per second, number of channels (1 for mono and 2 for stereo) and the number of bits used per channel sample in order to load an audio file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#These are the sample parameters for the files we'll be using:\n",
      "sampling_rate = 44100 #in Hz, the number of samples per second\n",
      "sample_size = np.int16 #16bit signed PCM\n",
      "audio_format = pa.paInt16#pa.paInt16\n",
      "channels = 2\n",
      "length_to_load = 30 #(seconds), set to -1 if you want to load the entire file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#audio loading\n",
      "print \"Loading\",\n",
      "background = './celtic-16bit-signed-44100hz-stereo.raw'\n",
      "audio_book_1984_ch2 = './1984-02-16bit-signed-44100hz-stereo.raw'\n",
      "file_1 = np.fromfile(background,dtype=sample_size,count=length_to_load*sampling_rate*channels)\n",
      "file_2 = np.fromfile(audio_book_1984_ch2,dtype=sample_size,count=length_to_load*sampling_rate*channels)\n",
      "print \" <SUCCESS>\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Normally before we compare two files we need to to normalize them to the same \"average\" volume. The Root Mean Squared (RMS) value is an indication of this \"average\" sample volume and is computed as:\n",
      "\\begin{equation}\n",
      " RMS = \\sqrt{\\frac{1}{M}\\sum_{i=0}^{M-1}{x_i^2}}\n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Normalize file 1 to the rms of file 2\n",
      "rms_desired_L = np.sqrt(np.mean(file_2[::2].astype(np.float)**2))\n",
      "rms_desired_R = np.sqrt(np.mean(file_2[1::2].astype(np.float)**2))\n",
      "rms_current_L = np.sqrt(np.mean(file_1[::2].astype(np.float)**2))\n",
      "rms_current_R = np.sqrt(np.mean(file_1[1::2].astype(np.float)**2))\n",
      "file_1[::2] = (file_1[::2].astype(np.float) * rms_desired_L / rms_current_L).astype(sample_size)\n",
      "file_1[1::2] = (file_1[1::2].astype(np.float) * rms_desired_R / rms_current_R).astype(sample_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The volume (per channel) is simply adjusted, by multiplying through by a constant:\n",
      "\\begin{equation}\n",
      "    \\begin{split}\n",
      "        L_i &= cL_i \\text{ where } 0{\\leq}c{\\leq}1.0\\text{ for each channel sample } L_i\\\\\n",
      "        R_i &= dR_i \\text{ where } 0{\\leq}d{\\leq}1.0\\text{ for each channel sample } R_i\\\\\n",
      "    \\end{split}\n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Adjust Volume\n",
      "file_1_L = 0.25\n",
      "file_1_R = 0.25\n",
      "file_2_L = 1\n",
      "file_2_R = 1\n",
      "file_1[::2] = (file_1[::2].astype(np.float) * file_1_L).astype(sample_size)\n",
      "file_1[1::2] = (file_1[1::2].astype(np.float) * file_1_R).astype(sample_size)\n",
      "file_2[::2] = (file_2[::2].astype(np.float) * file_2_L).astype(sample_size)\n",
      "file_2[1::2] = (file_2[1::2].astype(np.float) * file_2_R).astype(sample_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot amplitudes\n",
      "plt.figure(figsize=(15, 6), dpi=300)\n",
      "plt.title(\"George Orwell - 1984 - chapter 2 (Left Channel)\")\n",
      "plt.xlabel(\"Seconds\")\n",
      "plt.ylabel(\"Amplitude\")\n",
      "t = np.arange(length_to_load * sampling_rate)/float(sampling_rate)\n",
      "plt.plot(t,file_2[::2])\n",
      "plt.figure(figsize=(15, 6), dpi=300)\n",
      "plt.title(\"George Orwell - 1984 - chapter 2 (Right Channel)\")\n",
      "plt.xlabel(\"Seconds\")\n",
      "plt.ylabel(\"Amplitude\")\n",
      "plt.plot(t,file_2[1::2])\n",
      "plt.figure(figsize=(15, 6), dpi=300)\n",
      "plt.title(\"Background Music (Left Channel)\")\n",
      "plt.xlabel(\"Seconds\")\n",
      "plt.ylabel(\"Amplitude\")\n",
      "plt.plot(t,file_1[::2])\n",
      "plt.figure(figsize=(15, 6), dpi=300)\n",
      "plt.title(\"Background Music (Right Channel)\")\n",
      "plt.xlabel(\"Seconds\")\n",
      "plt.ylabel(\"Amplitude\")\n",
      "plt.plot(t,file_1[1::2])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compute RMS\n",
      "print \"RMS 1984 - George Orwel (Left):\",np.sqrt(np.mean(file_2[::2].astype(np.float)**2))\n",
      "print \"RMS 1984 - George Orwel (Right):\",np.sqrt(np.mean(file_2[1::2].astype(np.float)**2))\n",
      "print \"RMS Background Music (Left):\",np.sqrt(np.mean(file_1[::2].astype(np.float)**2))\n",
      "print \"RMS Background Music (Right):\",np.sqrt(np.mean(file_1[1::2].astype(np.float)**2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#play audio file two (1984 - ch 2)\n",
      "current_time_tic = time.time()\n",
      "p = pa.PyAudio()\n",
      "stream = p.open(format=audio_format,\n",
      "                channels=2,\n",
      "                rate=sampling_rate,\n",
      "                output=True)\n",
      "stream.write(file_2.tostring())\n",
      "stream.stop_stream()\n",
      "stream.close()\n",
      "p.terminate()\n",
      "current_time_toc = time.time()\n",
      "print \"Elapsed time\", current_time_toc - current_time_tic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All audio is linear. This means when we add a telephone conversion between Bill and Bob with a telephone conversation between Mandy and Eve, we would expect to hear Bill, Bob, Mandy and Eve talking. If we add the audio book and the background music we should expect the background music and the audio book to be played simultanuously."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Adding signals\n",
      "output_1984_with_background_music = np.clip((file_1.astype(float) + file_2.astype(float)),\n",
      "                                            np.iinfo(sample_size).min,np.iinfo(sample_size).max).astype(sample_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot amplitudes\n",
      "plt.figure(figsize=(15, 6), dpi=300)\n",
      "plt.title(\"1984 with background music (Left Channel)\")\n",
      "plt.xlabel(\"Seconds\")\n",
      "plt.ylabel(\"Amplitude\")\n",
      "t = np.arange(length_to_load * sampling_rate)/float(sampling_rate)\n",
      "plt.plot(t,output_1984_with_background_music[::2])\n",
      "plt.figure(figsize=(15, 6), dpi=300)\n",
      "plt.title(\"1984 with background music (Right Channel)\")\n",
      "plt.xlabel(\"Seconds\")\n",
      "plt.ylabel(\"Amplitude\")\n",
      "plt.plot(t,output_1984_with_background_music[1::2])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compute RMS\n",
      "print \"RMS 1984 with background music (Left):\",np.sqrt(np.mean(output_1984_with_background_music[::2].astype(np.float)**2))\n",
      "print \"RMS 1984 with background music (Right):\",np.sqrt(np.mean(output_1984_with_background_music[1::2].astype(np.float)**2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#play the addition between the two files (audiobook with background music)\n",
      "current_time_tic = time.time()\n",
      "p = pa.PyAudio()\n",
      "stream = p.open(format=audio_format,\n",
      "                channels=channels,\n",
      "                rate=sampling_rate,\n",
      "                output=True)\n",
      "stream.write(output_1984_with_background_music.tostring())\n",
      "stream.stop_stream()\n",
      "stream.close()\n",
      "p.terminate()\n",
      "current_time_toc = time.time()\n",
      "print \"Elapsed time\", current_time_toc - current_time_tic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Fade-in Fade-out"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fading in and out can be achieved by applying a linear scaling factor to amplitudes within the first and last N samples of a file. The values are scaled linearly using the following formulae (per channel):\n",
      "\n",
      "Fade-in:\n",
      "\\begin{equation}\n",
      "x_j = (j / L)x_j\\text{ for } j\\in[0,L)\n",
      "\\end{equation}\n",
      "Fade-out:\n",
      "\\begin{equation}\n",
      "x_{end-L+j} = (1 - j / L)x_{end-L+j}\\text{ for } j\\in[0,L)\n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Tone generator\n",
      "print \"Generating tone\",\n",
      "frequencies = {'B8' : 7902.13, 'C4' : 261.63} #Hz (these should be maximum 0.5 * sampling rate - otherwise bad things happen (aka aliasing)\n",
      "#Note: this should be at least 2 * highest frequency to satisfy nyquest sampling\n",
      "tone_length = 25.00 #seconds\n",
      "sampling_rate = 44100 #in Hz, the number of samples per second\n",
      "sample_size = np.float32 #16bit signed PCM\n",
      "audio_format = pa.paFloat32\n",
      "channels = 1 #left and right\n",
      "vol_chan_1 = 1.0 #100%\n",
      "audio = (np.sin(2 * np.pi * frequencies['C4'] / sampling_rate * \n",
      "                   np.arange(0,tone_length*sampling_rate,dtype=np.float32)) * \n",
      "                    vol_chan_1)\n",
      "print \" <SUCCESS>\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#settings for the linear ramp\n",
      "ramp_length = 10\n",
      "assert(ramp_length <= tone_length)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Apply a linear ramp to the the tone (fade in / fade out)\n",
      "ramp_length_in_samples = ramp_length * sampling_rate\n",
      "ramp_in = np.arange(0,ramp_length_in_samples,dtype=np.float32)/ramp_length_in_samples\n",
      "ramp_out = 1.0-np.arange(0,ramp_length_in_samples,dtype=np.float32)/ramp_length_in_samples\n",
      "audio[:ramp_length_in_samples] *= ramp_in\n",
      "audio[len(audio)-ramp_length_in_samples:] *= ramp_out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#play the ramped tone\n",
      "import time\n",
      "current_time_tic = time.time()\n",
      "p = pa.PyAudio()\n",
      "stream = p.open(format=audio_format,\n",
      "                channels=channels,\n",
      "                rate=sampling_rate,\n",
      "                output=1)\n",
      "\n",
      "stream.write(audio.tostring())\n",
      "\n",
      "stream.stop_stream()\n",
      "stream.close()\n",
      "p.terminate()\n",
      "current_time_toc = time.time()\n",
      "print \"Elapsed time\", current_time_toc - current_time_tic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}